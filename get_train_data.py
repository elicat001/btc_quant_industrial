# File: get_train_data.py
# ä¼˜åŒ–ï¼šæ·»åŠ åˆ†é¡µæ‹‰å–å®Œæ•´å†å²æ•°æ®ã€‚ç»Ÿä¸€ç‰¹å¾ä¸º7ç»´ï¼ˆåŠ spread/imbalanceè¿‘ä¼¼ï¼‰ã€‚ä½¿ç”¨ta-libåŠ é€ŸæŒ‡æ ‡ã€‚æ·»åŠ æ ‡å‡†åŒ–å¹¶ä¿å­˜scalerã€‚ä»configåŠ è½½å‚æ•°ã€‚

import pandas as pd
import numpy as np
import requests
import time
import joblib
from sklearn.preprocessing import StandardScaler
import talib  # æ–°å¢ta-lib
import yaml

with open("config.yaml", "r") as f:
    config = yaml.safe_load(f)
symbol = config.get("symbol", "BTCUSDT")
interval = config.get("interval", "1m")
lookback_hours = config.get("lookback_hours", 48)

def fetch_klines():
    print("ğŸ“¥ æ­£åœ¨ä» Binance è·å–å†å²Kçº¿æ•°æ®...")
    url = f"https://api.binance.com/api/v3/klines"
    end_time = int(time.time() * 1000)
    start_time = end_time - lookback_hours * 60 * 60 * 1000
    data = []
    while start_time < end_time:
        params = {"symbol": symbol, "interval": interval, "startTime": start_time, "endTime": end_time, "limit": 1000}
        response = requests.get(url, params=params)
        batch = response.json()
        if not batch:
            break
        data.extend(batch)
        start_time = batch[-1][0] + 1
    df = pd.DataFrame(data, columns=["time", "open", "high", "low", "close", "volume", "close_time", "quote_asset_volume", "number_of_trades", "taker_buy_base_asset_volume", "taker_buy_quote_asset_volume", "ignore"])
    df["time"] = pd.to_datetime(df["time"], unit="ms")
    df[["open", "high", "low", "close", "volume"]] = df[["open", "high", "low", "close", "volume"]].astype(float)
    return df

df = fetch_klines()

# æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ using ta-lib
df["ema"] = talib.EMA(df["close"], timeperiod=14)
df["rsi"] = talib.RSI(df["close"], timeperiod=14)
df["macd"], _, _ = talib.MACD(df["close"], fastperiod=12, slowperiod=26, signalperiod=9)

# è¿‘ä¼¼spread/imbalance
df["spread_approx"] = df["high"] - df["low"]
df["imbalance_approx"] = (df["taker_buy_base_asset_volume"] - (df["volume"] - df["taker_buy_base_asset_volume"])) / (df["volume"] + 1e-6)

# åˆ›å»ºæœªæ¥æ”¶ç›Šç‡
future_shift = config.get("future_shift", 5)
df["future_return"] = (df["close"].shift(-future_shift) - df["close"]) / df["close"]

# ä¿ç•™7ç»´ç‰¹å¾ + æ ‡ç­¾
train_df = df[["close", "volume", "rsi", "macd", "ema", "spread_approx", "imbalance_approx", "future_return"]].dropna()

# æ ‡å‡†åŒ–å¹¶ä¿å­˜scaler
scaler = StandardScaler()
train_df.iloc[:, :-1] = scaler.fit_transform(train_df.iloc[:, :-1])
joblib.dump(scaler, "scaler.pkl")

train_df.to_csv("train_data.csv", index=False)
print(f"âœ… å·²ç”Ÿæˆ train_data.csv, å…± {len(train_df)} æ¡æ•°æ®")